# ragone
RAG One

â¸»

ğŸ“Œ Directory Structure

rag-service/
â”‚â”€â”€ docker-compose.yml
â”‚â”€â”€ Dockerfile
â”‚â”€â”€ app/
â”‚   â”‚â”€â”€ main.py          # RAG pipeline
â”‚   â”‚â”€â”€ ingestion.py     # Document ingestion
â”‚   â”‚â”€â”€ requirements.txt # Dependencies


â¸»

ğŸ“Œ Step 6: Running the Service

1ï¸âƒ£ Start the service:

docker-compose up --build

2ï¸âƒ£ Ingest a document:

docker exec -it rag_pipeline python ingestion.py

3ï¸âƒ£ Query the RAG service:

curl "http://localhost:8000/query?q=What is AI?"


â¸»

ğŸ”¹ Why Use BAAI/bge-reranker-base for Reranking?

âœ… More Accurate Reranking â†’ Uses cross-encoder ranking instead of simple vector similarity.
âœ… Better Query-Document Matching â†’ Focuses on semantic relationships, not just cosine similarity.
âœ… Improves Final Response Quality â†’ Ensures the best documents are selected before response generation.

â¸»


ğŸ“Œ Summary
	â€¢	Document Extraction â†’ Docling
	â€¢	Vector Search â†’ Qdrant
	â€¢	Embedding Model â†’ DeepSeek
	â€¢	Reranking â†’ âœ… BAAI/bge-reranker-base
	â€¢	Response Generation â†’ DeepSeek LLM
	â€¢	API Interface â†’ FastAPI
	â€¢	Graph-based Execution â†’ LangGraph

